{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP/ZbaHK8cxmPafsyP52uOy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f35f22f8c2704885bce8eef0112540fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cf1c0989288a45c6b3bd3be34019deb8",
              "IPY_MODEL_ac1b7673cfe9483081dbaa2a29abe292",
              "IPY_MODEL_80eecb4e92ae43a2ba835d7961129327"
            ],
            "layout": "IPY_MODEL_55f5f337ccb741beb161113a54beb368"
          }
        },
        "cf1c0989288a45c6b3bd3be34019deb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f7eb082cc614ad1845d992bf7f51fa7",
            "placeholder": "​",
            "style": "IPY_MODEL_251bf970df0b416abbcebb1ab4bcc7d8",
            "value": "  1%"
          }
        },
        "ac1b7673cfe9483081dbaa2a29abe292": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc689785b14e423e91c9befda902f1b6",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c12cefb370754890ad8747d6e85faa5c",
            "value": 11
          }
        },
        "80eecb4e92ae43a2ba835d7961129327": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bccdf46b54784d4c85ccd284650d70e5",
            "placeholder": "​",
            "style": "IPY_MODEL_373af9eda28849c08095953e4362fc1c",
            "value": " 11/1000 [03:41&lt;5:07:51, 18.68s/it]"
          }
        },
        "55f5f337ccb741beb161113a54beb368": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f7eb082cc614ad1845d992bf7f51fa7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "251bf970df0b416abbcebb1ab4bcc7d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc689785b14e423e91c9befda902f1b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c12cefb370754890ad8747d6e85faa5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bccdf46b54784d4c85ccd284650d70e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "373af9eda28849c08095953e4362fc1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sojinleeme/colab_InverseProblem/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install piq blobfile mpi4py torchinfo wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fmYO_Kf4mtZ",
        "outputId": "c3aa34ad-bf85-4e15-a829-7c0a9748b78f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: piq in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Requirement already satisfied: blobfile in /usr/local/lib/python3.10/dist-packages (2.0.2)\n",
            "Requirement already satisfied: mpi4py in /usr/local/lib/python3.10/dist-packages (3.1.4)\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.15.8)\n",
            "Requirement already satisfied: torchvision>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from piq) (0.15.2+cu118)\n",
            "Requirement already satisfied: pycryptodomex~=3.8 in /usr/local/lib/python3.10/dist-packages (from blobfile) (3.18.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from blobfile) (2.0.4)\n",
            "Requirement already satisfied: lxml~=4.9 in /usr/local/lib/python3.10/dist-packages (from blobfile) (4.9.3)\n",
            "Requirement already satisfied: filelock~=3.0 in /usr/local/lib/python3.10/dist-packages (from blobfile) (3.12.2)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.32)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.29.2)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.10/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.10.0->piq) (1.23.5)\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.10.0->piq) (2.0.1+cu118)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.10.0->piq) (9.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision>=0.10.0->piq) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision>=0.10.0->piq) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision>=0.10.0->piq) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision>=0.10.0->piq) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision>=0.10.0->piq) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision>=0.10.0->piq) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision>=0.10.0->piq) (16.0.6)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->torchvision>=0.10.0->piq) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->torchvision>=0.10.0->piq) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/sojinleeme/colab_InverseProblem.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51XOHVnbHpar",
        "outputId": "299f3207-cda4-4e7d-cf17-b8dca1298753"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'colab_InverseProblem' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/colab_InverseProblem"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnvYi6zYHr3u",
        "outputId": "2e652f76-e43d-4bea-b47f-45c1fe4b0b9a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/colab_InverseProblem\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVc0XaZ63Vg8",
        "outputId": "99b79597-b077-4ed5-a23b-322115ed99f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘models’: File exists\n",
            "mkdir: cannot create directory ‘models/ffhq_1k’: File exists\n",
            "fatal: destination path 'motionblur' already exists and is not an empty directory.\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1eIMU9te-Y0rC3J7mYtApxhbEpueWsVeq\n",
            "To: /content/colab_InverseProblem/ffhq_10m.pt\n",
            "100% 374M/374M [00:03<00:00, 99.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "!mkdir models\n",
        "!mkdir models/ffhq_1k\n",
        "!git clone https://github.com/LeviBorodenko/motionblur.git\n",
        "!gdown --id 1eIMU9te-Y0rC3J7mYtApxhbEpueWsVeq\n",
        "!mv ffhq_10m.pt models/ffhq_1k/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Generate a large batch of image samples from a model and save them as a large\n",
        "numpy array. This can be used to produce samples for FID evaluation.\n",
        "\"\"\"\n",
        "from functools import partial\n",
        "import argparse\n",
        "import os, sys\n",
        "# sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(__file__))))\n",
        "sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname('/content/colab_InverseProblem'))))\n",
        "\n",
        "import yaml\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from piq import LPIPS\n",
        "import numpy as np\n",
        "import torch as th\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from util.img_utils import clear_color, mask_generator, add_caption_to_image\n",
        "from data.dataloader import get_dataset, get_dataloader\n",
        "\n",
        "from cm import dist_util, logger\n",
        "from cm.nn import mean_flat\n",
        "from guided_diffusion.condition_methods import get_conditioning_method\n",
        "from guided_diffusion.measurements import get_noise, get_operator\n",
        "from guided_diffusion.svd_operators import Deblurring, SRConv\n",
        "from guided_diffusion.gram_util import GramModel\n",
        "from torchinfo import summary\n",
        "import torchvision.utils as vtils\n",
        "\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr_loss\n",
        "from skimage.metrics import structural_similarity as ssim_loss\n",
        "\n",
        "from guided_diffusion.script_util_nonblind_grammatrix import(\n",
        "    NUM_CLASSES,\n",
        "    model_and_diffusion_defaults, # AFHQ\n",
        "    ffhq_model_and_diffusion_defaults, # FFHQ\n",
        "    imagenet_model_and_diffusion_defaults, # ImageNet\n",
        "    create_model_and_diffusion,\n",
        "    add_dict_to_argparser,\n",
        "    args_to_dict,\n",
        ")\n",
        "\n",
        "def load_yaml(file_path: str) -> dict:\n",
        "    with open(file_path) as f:\n",
        "        config = yaml.load(f, Loader=yaml.FullLoader)\n",
        "    return config\n",
        "\n",
        "def set_random_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    th.manual_seed(seed)\n",
        "    th.cuda.manual_seed_all(seed)\n",
        "\n",
        "def mkdir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "def list_of_strings(arg):\n",
        "    return arg.split(',')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDrOtN8C5oHB",
        "outputId": "d3c4bfcc-97c4-4425-9519-1a1bf66ae1bc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_argparser():\n",
        "    defaults = dict(\n",
        "        num_samples=1000,\n",
        "        batch_size=1,\n",
        "        steps=1000,\n",
        "        seed=42,\n",
        "    )\n",
        "\n",
        "    from guided_diffusion.script_util_nonblind_grammatrix import model_and_diffusion_defaults, add_dict_to_argparser\n",
        "\n",
        "    defaults.update(model_and_diffusion_defaults())\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    parser.add_argument('--gpu', type=str, default='6')\n",
        "    parser.add_argument('--task_config', type=str, default='configs/noise_0.05/gaussian_deblur_config.yaml')\n",
        "\n",
        "    parser.add_argument('--exp_name', type=str, default='GramB')\n",
        "    parser.add_argument('--log_dir', type=str, default='./results_toy/0821_GramDebug')\n",
        "    parser.add_argument('-log','--log_suffix', type=str)\n",
        "    parser.add_argument('--model_path', type=str, default='models/ffhq_1k/ffhq_10m.pt')\n",
        "\n",
        "    parser.add_argument('--use_wandb', action='store_true', default=False)\n",
        "    parser.add_argument('--no_encoding', action='store_true', default=False)\n",
        "    parser.add_argument('--ddpm', action='store_true', default=True)\n",
        "    parser.add_argument('--run', action='store_true', default=False)\n",
        "    parser.add_argument('--debug_mode', action='store_true', default=False)\n",
        "\n",
        "    parser.add_argument('--diffusion_steps', type=int, default=1000)\n",
        "    parser.add_argument('--toyver', type=int, default=1)\n",
        "\n",
        "    parser.add_argument('--norm_loss', type=float, default=0.1)\n",
        "    parser.add_argument('--reg_dps', type=float, default=1)\n",
        "    parser.add_argument('--reg_style', type=float, default=1000)\n",
        "    parser.add_argument('--reg_content', type=float, default=100)\n",
        "\n",
        "    parser.add_argument('--layer_style', type=list, default=['conv_5'])\n",
        "    parser.add_argument('--layer_content', type=list, default=['conv_2'])\n",
        "\n",
        "    add_dict_to_argparser(parser, defaults)\n",
        "    return parser"
      ],
      "metadata": {
        "id": "VS24v7aQ9SSp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # args = create_argparser().parse_args()\n",
        "    # args = parser.parse_args(args=[])\n",
        "    args = create_argparser().parse_args(args=[])\n",
        "    set_random_seed(args.seed)\n",
        "\n",
        "    task_config = load_yaml(args.task_config)\n",
        "    measure_config = task_config['measurement']\n",
        "    task_name = measure_config['operator']['name']\n",
        "\n",
        "    norm_dict = {\"loss\":args.norm_loss, \"reg_dps\":args.reg_dps, \"reg_style\":args.reg_style, \"reg_content\":args.reg_content, \\\n",
        "                 }\n",
        "\n",
        "    if args.log_suffix is not None:\n",
        "        args.log_suffix = f'{args.log_suffix}_{args.exp_name}'\n",
        "\n",
        "    args.sub_directory = f'{task_name}_toyver{args.toyver}/{args.exp_name}/time{args.diffusion_steps}normL{args.norm_loss}'\n",
        "\n",
        "    if \"Gram\" in args.exp_name:\n",
        "        lay_sty = '_'.join(args.layer_style)\n",
        "        lay_con = '_'.join(args.layer_content)\n",
        "        args.log_suffix = f'{args.sub_directory}/laySty{lay_sty}_layCon{lay_con}/regDPS{args.reg_dps}regSty{args.reg_style}_regCon{args.reg_content}'\n",
        "    else:\n",
        "        args.log_suffix = f'{args.sub_directory}/regDPS{args.reg_dps}'\n",
        "\n",
        "    # set save directory\n",
        "    if args.run:\n",
        "        args.global_result_path = os.path.join(args.log_dir, 'total_results')\n",
        "        mkdir(args.global_result_path)\n",
        "\n",
        "        # args.sub_result_path = os.path.join(args.log_dir, args.sub_directory, 'sub_results')\n",
        "        # mkdir(args.sub_result_path)\n",
        "\n",
        "    args.log_dir = os.path.join(args.log_dir, args.log_suffix)\n",
        "    args.save_dir = args.log_dir\n",
        "    mkdir(args.save_dir)\n",
        "\n",
        "    dist_util.setup_dist(args.gpu)\n",
        "    logger.configure(dir=args.save_dir)\n",
        "\n",
        "    logger.log(\"creating model and diffusion...\")\n",
        "    if 'ffhq' in args.model_path:\n",
        "        image_dict = args_to_dict(args, ffhq_model_and_diffusion_defaults().keys())\n",
        "        image_dict.update(ffhq_model_and_diffusion_defaults())\n",
        "        args.wandb_table = 'Model:FFHQ'\n",
        "    elif 'imagenet' in args.model_path:\n",
        "        image_dict = args_to_dict(args, imagenet_model_and_diffusion_defaults().keys())\n",
        "        image_dict.update(imagenet_model_and_diffusion_defaults())\n",
        "        args.wandb_table = 'Model:ImageNet'\n",
        "    else:\n",
        "        NotImplementedError()\n",
        "\n",
        "    diffusion_dict = {'diffusion_steps':args.diffusion_steps}\n",
        "    image_dict.update(diffusion_dict)\n",
        "\n",
        "    model, diffusion = create_model_and_diffusion(\n",
        "        **image_dict,\n",
        "    )\n",
        "\n",
        "    model.load_state_dict(\n",
        "        dist_util.load_state_dict(args.model_path, map_location=\"cpu\")\n",
        "    )\n",
        "    model.to(dist_util.dev())\n",
        "    if args.use_fp16:\n",
        "        model.convert_to_fp16()\n",
        "    model.eval()\n",
        "\n",
        "    th.set_default_device(dist_util.dev())\n",
        "    # Prepare VGG Network for Gram Matrix\n",
        "    # vgg_cnn = models.vgg19(pretrained=True).to(dist_util.dev())\n",
        "    # vgg_cnn = vgg_cnn.features.eval()\n",
        "    vgg_cnn = models.vgg19(pretrained=True).features.eval()\n",
        "\n",
        "    # Prepare Operator and noise\n",
        "    if measure_config['operator']['name'] == 'gaussian_blur':\n",
        "        sigma = measure_config['operator']['intensity']\n",
        "        kernel_size = measure_config['operator']['kernel_size']\n",
        "\n",
        "        def pdf(x, sigma=sigma):\n",
        "            return th.exp(th.Tensor([-0.5 * (x / sigma) ** 2]))\n",
        "\n",
        "        kernel = th.Tensor([pdf(i) for i in range(-int(kernel_size//2), int(kernel_size//2)+1)])\n",
        "        operator = Deblurring(kernel / kernel.sum(), 3, 256, dist_util.dev())\n",
        "\n",
        "    elif measure_config['operator']['name'] == 'super_resolution': # bicubic\n",
        "        factor = measure_config['operator']['scale_factor']\n",
        "\n",
        "        def bicubic_kernel(x, a=-0.5):\n",
        "            if abs(x) <= 1:\n",
        "                return (a + 2) * abs(x) ** 3 - (a + 3) * abs(x) ** 2 + 1\n",
        "            elif 1 < abs(x) and abs(x) < 2:\n",
        "                return a * abs(x) ** 3 - 5 * a * abs(x) ** 2 + 8 * a * abs(x) - 4 * a\n",
        "            else:\n",
        "                return 0\n",
        "        k = np.zeros((factor * 4))\n",
        "        for i in range(factor * 4):\n",
        "            x = (1 / factor) * (i - np.floor(factor * 4 / 2) + 0.5)\n",
        "            k[i] = bicubic_kernel(x)\n",
        "        k = k / np.sum(k)\n",
        "        kernel = th.from_numpy(k).float().to(dist_util.dev())\n",
        "        operator = SRConv(kernel / kernel.sum(), 3, 256, dist_util.dev(), stride=factor)\n",
        "\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "    # operator_default = get_operator(device=dist_util.dev(), **measure_config['operator'])\n",
        "    noiser = get_noise(**measure_config['noise'])\n",
        "    logger.info(f\"Operation: {measure_config['operator']['name']} / Noise: {measure_config['noise']['name']}\")\n",
        "\n",
        "    # Prepare conditioning method\n",
        "    cond_config = task_config['conditioning']\n",
        "    cond_method = get_conditioning_method(cond_config['method'], operator, noiser, **cond_config['params'])\n",
        "    measurement_cond_fn = cond_method.conditioning\n",
        "    logger.info(f\"Conditioning method : {task_config['conditioning']['method']}\")\n",
        "\n",
        "    # Working directory\n",
        "    out_path = os.path.join(args.save_dir, measure_config['operator']['name'])\n",
        "    os.makedirs(out_path, exist_ok=True)\n",
        "\n",
        "    # Prepare dataloader\n",
        "    data_config = task_config['data']\n",
        "\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "    dataset = get_dataset(**data_config, transforms=transform)\n",
        "    loader = get_dataloader(dataset, batch_size=1, num_workers=0, train=False)\n",
        "\n",
        "    # Exception) In case of inpainting, we need to generate a mask\n",
        "    if measure_config['operator']['name'] == 'inpainting':\n",
        "        mask_gen = mask_generator(\n",
        "           **measure_config['mask_opt']\n",
        "        )\n",
        "\n",
        "    if args.use_wandb:\n",
        "        import wandb\n",
        "        table_name = f\"{args.wandb_table}_{args.exp_name}\"\n",
        "        wandb.init(project=\"toy\", name=table_name)\n",
        "        wandb.config.update(args)\n",
        "\n",
        "    lpips = LPIPS(replace_pooling=True, reduction=\"none\")\n",
        "\n",
        "\n",
        "    for i, ref_img in enumerate(loader):\n",
        "        logger.info(f\"Inference for image {i}\")\n",
        "        fname = str(i).zfill(5) + '.png'\n",
        "        ref_img = ref_img.to(dist_util.dev())\n",
        "        ref_img = ref_img * 2 - 1\n",
        "\n",
        "        # Exception) In case of inpainging,\n",
        "        if measure_config['operator'] ['name'] == 'inpainting':\n",
        "            mask = mask_gen(ref_img)\n",
        "            mask = mask[:, 0, :, :].unsqueeze(dim=0)\n",
        "            measurement_cond_fn = partial(cond_method.conditioning, mask=mask)\n",
        "\n",
        "            # Forward measurement model (Ax + n)\n",
        "            y = operator.A(ref_img, mask=mask)\n",
        "        else:\n",
        "            # Forward measurement model (Ax + n)\n",
        "            y = operator.A(ref_img)\n",
        "\n",
        "        b, hwc = y.size()\n",
        "        hw = hwc / 3\n",
        "        h = w = int(hw ** 0.5)\n",
        "        y = y.reshape((b, 3, h, w))\n",
        "\n",
        "        y_n = noiser(y)\n",
        "        y_measurement = y_n.clone()\n",
        "        plt.imsave(os.path.join(out_path, f'label{fname}'), clear_color(ref_img))\n",
        "        plt.imsave(os.path.join(out_path, f'y{fname}'), clear_color(y))\n",
        "        plt.imsave(os.path.join(out_path, f'y_n{fname}'), clear_color(y_n))\n",
        "\n",
        "        forward_dir = f'{args.save_dir}/{i}_for_'\n",
        "        backward_dir = f'{args.save_dir}/{i}_back_'\n",
        "\n",
        "        x_start = y_n.requires_grad_()\n",
        "\n",
        "        if 'Gram' in args.exp_name:\n",
        "            if 'cleanGT' in args.exp_name:\n",
        "                logger.log(f'! ! ! Clean GT TEST ! ! !')\n",
        "                gram_model = GramModel(cnn=vgg_cnn, style_img=ref_img, content_img=ref_img, content_layers=args.layer_content, style_layers=args.layer_style)\n",
        "            else:\n",
        "                gram_model = GramModel(cnn=vgg_cnn, style_img=y_n, content_img=y_n, content_layers=args.layer_content, style_layers=args.layer_style)\n",
        "            gram_model = gram_model.to(dist_util.dev())\n",
        "            gram_model.eval()\n",
        "            gram_model.requires_grad_(False)\n",
        "        else:\n",
        "            gram_model = None\n",
        "\n",
        "        if args.ddpm:\n",
        "            logger.log(f\"############ DDPM ############\")\n",
        "\n",
        "            noise = th.randn(1, 3, 256, 256, device=dist_util.dev())\n",
        "            sample_restored = diffusion.p_sample_loop(\n",
        "                model,\n",
        "                (args.batch_size, 3, 256, 256),\n",
        "                noise=noise,\n",
        "                operator=operator,\n",
        "                clip_denoised=True,\n",
        "                device=dist_util.dev(),\n",
        "                progress=True,\n",
        "                use_wandb=args.use_wandb,\n",
        "                directory=backward_dir,\n",
        "                original_image=ref_img,\n",
        "                debug_mode=args.debug_mode,\n",
        "                toyver=args.toyver,\n",
        "                norm=norm_dict,\n",
        "                measurement_cond_fn=measurement_cond_fn,\n",
        "                y0_measurement=y_measurement,\n",
        "                gram_model=gram_model,\n",
        "                exp_name=args.exp_name\n",
        "            )\n",
        "        else:\n",
        "            logger.log(f\"!!!!!!!!!!! DDIM !!!!!!!!!!!\")\n",
        "\n",
        "            if args.no_encoding:\n",
        "                logger.log(f\"Random Noise...\")\n",
        "                noise_restored = th.randn(1, 3, 256, 256, device=dist_util.dev())\n",
        "            else:\n",
        "                logger.log(\"Reverse DDIM: encoding the source images.\")\n",
        "                noise_restored = diffusion.ddim_reverse_sample_loop(\n",
        "                    model,\n",
        "                    image=x_start,\n",
        "                    operator=operator,\n",
        "                    clip_denoised=True,\n",
        "                    original_image=ref_img, # for PSNR, SSIM\n",
        "                    device=dist_util.dev(),\n",
        "                    progress=True,\n",
        "                    use_wandb=args.use_wandb,\n",
        "                    directory=forward_dir,\n",
        "                    debug_mode=args.debug_mode,\n",
        "                    norm=norm_dict,\n",
        "                    toyver=args.toyver,\n",
        "                    measurement_cond_fn=measurement_cond_fn,\n",
        "                    y0_measurement=y_measurement,\n",
        "                    gram_model=gram_model,\n",
        "                    exp_name=args.exp_name,\n",
        "                )\n",
        "                logger.log(f\"obtained latent representation for restored images...\")\n",
        "            plt.imsave(os.path.join(out_path, f'ddim_noise{fname}'), clear_color(noise_restored))\n",
        "\n",
        "            sample_restored = diffusion.ddim_sample_loop(\n",
        "                model,\n",
        "                (args.batch_size, 3, 256, 256),\n",
        "                noise=noise_restored,\n",
        "                operator=operator,\n",
        "                clip_denoised=True,\n",
        "                device=dist_util.dev(),\n",
        "                progress=True,\n",
        "                use_wandb=args.use_wandb,\n",
        "                directory=backward_dir,\n",
        "                original_image=ref_img,\n",
        "                debug_mode=args.debug_mode,\n",
        "                norm=norm_dict,\n",
        "                toyver=args.toyver,\n",
        "                measurement_cond_fn=measurement_cond_fn,\n",
        "                y0_measurement=y_measurement,\n",
        "                gram_model=gram_model,\n",
        "                exp_name=args.exp_name\n",
        "            )\n",
        "            logger.log(f\"obtained reconstructed restored images...\")\n",
        "        plt.imsave(os.path.join(out_path, f'Recon{fname}'), clear_color(sample_restored))\n",
        "\n",
        "        l2_loss = (ref_img - sample_restored) ** 2\n",
        "        l2_loss = mean_flat(l2_loss) # * weights\n",
        "        l2_loss = l2_loss.mean()\n",
        "\n",
        "        lpips_loss = lpips((sample_restored + 1) / 2.0, (ref_img + 1) / 2.0) # * weights\n",
        "        lpips_loss = mean_flat(lpips_loss) # * weights\n",
        "\n",
        "        psnr, ssim = 0.0, 0.0\n",
        "        for idx in range(ref_img.shape[0]):\n",
        "            restored = th.clamp(sample_restored[idx], -1., 1.).cpu().detach().numpy()\n",
        "            target = th.clamp(ref_img[idx], -1., 1.).cpu().detach().numpy()\n",
        "            ps = psnr_loss(restored, target)\n",
        "            ss = ssim_loss(restored, target, data_range=2.0, multichannel=True, channel_axis=0)\n",
        "            psnr += ps\n",
        "            ssim += ss\n",
        "            result = f\"[PSNR]: %.4f, [SSIM]: %.4f\"% (ps, ss)+'\\n'\n",
        "            print(result)\n",
        "            logger.log(result)\n",
        "        psnr /= args.batch_size\n",
        "        ssim /= args.batch_size\n",
        "\n",
        "        loss_dict = {\"l2_loss\": l2_loss, \"lpips_loss\": lpips_loss}\n",
        "        if args.use_wandb:\n",
        "            wandb.log(loss_dict)\n",
        "\n",
        "        results = f'{i}th iter --->' + \"[PSNR]: %.4f, [SSIM]: %.4f, [L2 loss]: %.4f, [LPIPS loss]: %.4f\"% (psnr, ssim, l2_loss, lpips_loss) + '\\n'\n",
        "        logger.log(results)\n",
        "\n",
        "        if args.run:\n",
        "            dir_list = args.log_suffix.split('/')\n",
        "            total_path = os.path.join(args.global_result_path,'_'.join(dir_list[:2]))\n",
        "            mkdir(total_path)\n",
        "            recon_name = '_'.join(dir_list[2:])\n",
        "            img_path = os.path.join(total_path, f'{recon_name}.png')\n",
        "            plt.imsave(img_path, clear_color(sample_restored))\n",
        "\n",
        "            caption1 = 'psnr %.4f'% (psnr)\n",
        "            caption2 = 'ssim %.4f'% (ssim)\n",
        "\n",
        "            add_caption_to_image(img_path, caption1, caption2, font_path='/home/sojin/NaverNanumSquare/NanumFontSetup_TTF_SQUARE/NanumSquareB.ttf')\n",
        "\n",
        "            with open(os.path.join(args.global_result_path,'total_results.txt'),'a') as f:\n",
        "                save_name = '_'.join(dir_list[1:])\n",
        "                results = f'{save_name}\\n' + \"[PSNR]: %.4f, [SSIM]: %.4f, [L2 loss]: %.4f, [LPIPS loss]: %.4f\"% (psnr, ssim, l2_loss, lpips_loss) + '\\n\\n'\n",
        "                f.write(results)\n",
        "\n",
        "        if args.debug_mode and i ==0: return\n",
        "\n",
        "        return\n",
        "\n",
        "    logger.log(\"Completed\")\n"
      ],
      "metadata": {
        "id": "h1g14v7q5xYg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 855,
          "referenced_widgets": [
            "f35f22f8c2704885bce8eef0112540fb",
            "cf1c0989288a45c6b3bd3be34019deb8",
            "ac1b7673cfe9483081dbaa2a29abe292",
            "80eecb4e92ae43a2ba835d7961129327",
            "55f5f337ccb741beb161113a54beb368",
            "2f7eb082cc614ad1845d992bf7f51fa7",
            "251bf970df0b416abbcebb1ab4bcc7d8",
            "bc689785b14e423e91c9befda902f1b6",
            "c12cefb370754890ad8747d6e85faa5c",
            "bccdf46b54784d4c85ccd284650d70e5",
            "373af9eda28849c08095953e4362fc1c"
          ]
        },
        "id": "5ODCPt_h9jUQ",
        "outputId": "2f634374-4605-43a2-f78e-8777ebb2b0fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logging to ./results_toy/0821_GramDebug/gaussian_blur_toyver1/GramB/time1000normL0.1/layStyconv_5_layConconv_2/regDPS1regSty1000_regCon100\n",
            "creating model and diffusion...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Operation: gaussian_blur / Noise: gaussian\n",
            "Conditioning method : ps\n",
            "Inference for image 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py:62: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return func(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "############ DDPM ############\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f35f22f8c2704885bce8eef0112540fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time_scale 1.0000\n",
            "[PSNR]: 7.7981\n",
            "\n",
            "time_scale 1.0000\n",
            "[PSNR]: 5.7474\n",
            "\n",
            "time_scale 1.0000\n",
            "[PSNR]: 5.9212\n",
            "\n",
            "time_scale 1.0000\n",
            "[PSNR]: 5.9212\n",
            "\n",
            "time_scale 1.0000\n",
            "[PSNR]: 5.9212\n",
            "\n",
            "time_scale 1.0000\n",
            "[PSNR]: 5.9212\n",
            "\n",
            "time_scale 1.0000\n",
            "[PSNR]: 5.9212\n",
            "\n",
            "time_scale 1.0000\n",
            "[PSNR]: 5.9212\n",
            "\n",
            "time_scale 1.0000\n",
            "[PSNR]: 5.9212\n",
            "\n",
            "time_scale 1.0000\n",
            "[PSNR]: 5.9212\n",
            "\n",
            "time_scale 1.0000\n",
            "[PSNR]: 5.9212\n",
            "\n",
            "time_scale 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "None_GramB_time_time1000normL1.0_layStyconv_4_layConconv_2_regDPS0.0regSty1000.0_regCon-100.0\n",
        "[PSNR]: 27.5124, [SSIM]: 0.7706, [L2 loss]: 0.0071, [LPIPS loss]: 0.1862"
      ],
      "metadata": {
        "id": "dJyU0CYZ5Vza"
      }
    }
  ]
}